{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f3cdaf",
   "metadata": {},
   "source": [
    "# Mental Health Analysis - Model Testing\n",
    "\n",
    "This notebook demonstrates how to load trained models and test them on new data.\n",
    "\n",
    "## Overview\n",
    "- Load pre-trained models and preprocessing components\n",
    "- Test models on sample text\n",
    "- Demonstrate prediction pipeline\n",
    "- Evaluate model performance on test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b664184",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8672c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully! ✓\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "print(\"Libraries imported successfully! ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1a31f",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained Models and Components\n",
    "\n",
    "Loading all the saved models and preprocessing components from the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd5ccc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Best model (Logistic Regression) loaded successfully\n",
      "✓ Model accuracy: 0.7541\n",
      "\n",
      "All model accuracies during training:\n",
      "  - Bernoulli Naive Bayes: 0.6538\n",
      "  - Decision Tree: 0.6753\n",
      "  - Logistic Regression: 0.7541\n",
      "  - KNN: 0.5155\n",
      "\n",
      "Available classes: ['Anxiety' 'Bipolar' 'Depression' 'Normal' 'Personality disorder' 'Stress'\n",
      " 'Suicidal']\n",
      "Model ready for testing! ✓\n"
     ]
    }
   ],
   "source": [
    "# Load the TF-IDF vectorizer\n",
    "with open('models/tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Load the label encoder\n",
    "with open('models/label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# Load preprocessing pipeline\n",
    "with open('models/preprocessing_pipeline.pkl', 'rb') as f:\n",
    "    preprocessing_pipeline = pickle.load(f)\n",
    "\n",
    "# Load model information\n",
    "with open('models/model_info.pkl', 'rb') as f:\n",
    "    model_info = pickle.load(f)\n",
    "\n",
    "# Extract preprocessing components\n",
    "stemmer = preprocessing_pipeline['stemmer']\n",
    "lemmatizer = preprocessing_pipeline['lemmatizer']\n",
    "stopwords = preprocessing_pipeline['stopwords']\n",
    "\n",
    "# Load the best trained model\n",
    "with open('models/training_model.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Best model ({model_info['model_name']}) loaded successfully\")\n",
    "print(f\"✓ Model accuracy: {model_info['accuracy']:.4f}\")\n",
    "print(f\"\\nAll model accuracies during training:\")\n",
    "for name, acc in model_info['all_accuracies'].items():\n",
    "    print(f\"  - {name}: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\nAvailable classes: {label_encoder.classes_}\")\n",
    "print(\"Model ready for testing! ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73522298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract preprocessing components\n",
    "stemmer = preprocessing_pipeline['stemmer']\n",
    "lemmatizer = preprocessing_pipeline['lemmatizer']\n",
    "stopwords = preprocessing_pipeline['stopwords']\n",
    "\n",
    "# Define text_preprocessing function using loaded components\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    Basic text preprocessing: lowercase, remove non-alphabetic, remove stopwords.\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    # Join back to string\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37277484",
   "metadata": {},
   "source": [
    "## 3. Create Prediction Pipeline\n",
    "\n",
    "Define a complete pipeline function that can take raw text and return predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71174e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction pipeline created successfully! ✓\n"
     ]
    }
   ],
   "source": [
    "def predict_mental_health(text):\n",
    "    \"\"\"\n",
    "    Complete prediction pipeline for mental health classification using the best trained model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to classify\n",
    "    \n",
    "    Returns:\n",
    "        dict: Prediction results including class and confidence\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Text preprocessing\n",
    "        cleaned_text = text_preprocessing(text)\n",
    "        \n",
    "        # Step 2: Lemmatization\n",
    "        lemmatized_text = lemmatizer.lemmatize(cleaned_text)\n",
    "        \n",
    "        # Step 3: Tokenization\n",
    "        tokens = word_tokenize(lemmatized_text)\n",
    "        \n",
    "        # Step 4: Stemming\n",
    "        stemmed_tokens = ' '.join([stemmer.stem(str(token)) for token in tokens])\n",
    "        \n",
    "        # Step 5: Calculate numerical features\n",
    "        num_characters = len(text)\n",
    "        num_sentences = len(nltk.sent_tokenize(text))\n",
    "        \n",
    "        # Step 6: TF-IDF transformation\n",
    "        text_features = vectorizer.transform([stemmed_tokens])\n",
    "        \n",
    "        # Step 7: Combine features\n",
    "        numerical_features = np.array([[num_characters, num_sentences]])\n",
    "        combined_features = hstack([text_features, numerical_features])\n",
    "        \n",
    "        # Step 8: Make prediction using the best model\n",
    "        prediction = best_model.predict(combined_features)[0]\n",
    "        \n",
    "        # Get prediction probabilities if available\n",
    "        confidence = None\n",
    "        probabilities = None\n",
    "        if hasattr(best_model, 'predict_proba'):\n",
    "            probabilities = best_model.predict_proba(combined_features)[0]\n",
    "            confidence = np.max(probabilities)\n",
    "            # Create probability dictionary\n",
    "            prob_dict = {label_encoder.classes_[i]: prob for i, prob in enumerate(probabilities)}\n",
    "        else:\n",
    "            prob_dict = None\n",
    "        \n",
    "        # Decode the prediction\n",
    "        predicted_class = label_encoder.inverse_transform([prediction])[0]\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': predicted_class,\n",
    "            'confidence': confidence,\n",
    "            'probabilities': prob_dict,\n",
    "            'model_used': model_info['model_name'],\n",
    "            'processed_text': stemmed_tokens[:100] + '...' if len(stemmed_tokens) > 100 else stemmed_tokens,\n",
    "            'features': {\n",
    "                'num_characters': num_characters,\n",
    "                'num_sentences': num_sentences,\n",
    "                'num_tokens': len(tokens)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'predicted_class': None,\n",
    "            'confidence': None\n",
    "        }\n",
    "\n",
    "print(\"Prediction pipeline created successfully! ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad40b2a",
   "metadata": {},
   "source": [
    "## 4. Test with Sample Cases\n",
    "\n",
    "Let's test our prediction pipeline with various sample texts representing different mental health conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ab5e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing prediction pipeline with Logistic Regression model:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test Case 1:\n",
      "Text: I've been feeling really sad and hopeless lately. Nothing seems to bring me joy anymore and I just want to stay in bed all day.\n",
      "Expected: Depression\n",
      "--------------------------------------------------\n",
      "Prediction: Normal\n",
      "Confidence: 0.481\n",
      "Model: Logistic Regression\n",
      "Top 3 predictions:\n",
      "  1. Normal: 0.481\n",
      "  2. Depression: 0.285\n",
      "  3. Suicidal: 0.121\n",
      "================================================================================\n",
      "\n",
      "Test Case 2:\n",
      "Text: My heart races and I can't breathe properly when I'm in crowded places. I'm constantly worried about having a panic attack.\n",
      "Expected: Anxiety\n",
      "--------------------------------------------------\n",
      "Prediction: Anxiety\n",
      "Confidence: 0.552\n",
      "Model: Logistic Regression\n",
      "Top 3 predictions:\n",
      "  1. Anxiety: 0.552\n",
      "  2. Normal: 0.296\n",
      "  3. Stress: 0.145\n",
      "================================================================================\n",
      "\n",
      "Test Case 3:\n",
      "Text: I feel great today! The weather is beautiful and I'm excited about my new project at work. Life is good.\n",
      "Expected: Normal\n",
      "--------------------------------------------------\n",
      "Prediction: Normal\n",
      "Confidence: 0.971\n",
      "Model: Logistic Regression\n",
      "Top 3 predictions:\n",
      "  1. Normal: 0.971\n",
      "  2. Bipolar: 0.016\n",
      "  3. Depression: 0.006\n",
      "================================================================================\n",
      "\n",
      "Test Case 4:\n",
      "Text: I keep checking if I locked the door over and over again. I can't stop these repetitive thoughts and behaviors.\n",
      "Expected: OCD\n",
      "--------------------------------------------------\n",
      "Prediction: Normal\n",
      "Confidence: 0.889\n",
      "Model: Logistic Regression\n",
      "Top 3 predictions:\n",
      "  1. Normal: 0.889\n",
      "  2. Bipolar: 0.058\n",
      "  3. Depression: 0.032\n",
      "================================================================================\n",
      "\n",
      "Test Case 5:\n",
      "Text: I've been having trouble sleeping for weeks now. I just can't seem to get a good night's rest no matter what I try.\n",
      "Expected: Insomnia\n",
      "--------------------------------------------------\n",
      "Prediction: Normal\n",
      "Confidence: 0.879\n",
      "Model: Logistic Regression\n",
      "Top 3 predictions:\n",
      "  1. Normal: 0.879\n",
      "  2. Anxiety: 0.062\n",
      "  3. Stress: 0.030\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define test cases for different mental health conditions\n",
    "test_cases = [\n",
    "    {\n",
    "        'text': \"I've been feeling really sad and hopeless lately. Nothing seems to bring me joy anymore and I just want to stay in bed all day.\",\n",
    "        'expected': 'Depression'\n",
    "    },\n",
    "    {\n",
    "        'text': \"My heart races and I can't breathe properly when I'm in crowded places. I'm constantly worried about having a panic attack.\",\n",
    "        'expected': 'Anxiety'\n",
    "    },\n",
    "    {\n",
    "        'text': \"I feel great today! The weather is beautiful and I'm excited about my new project at work. Life is good.\",\n",
    "        'expected': 'Normal'\n",
    "    },\n",
    "    {\n",
    "        'text': \"I keep checking if I locked the door over and over again. I can't stop these repetitive thoughts and behaviors.\",\n",
    "        'expected': 'OCD'\n",
    "    },\n",
    "    {\n",
    "        'text': \"I've been having trouble sleeping for weeks now. I just can't seem to get a good night's rest no matter what I try.\",\n",
    "        'expected': 'Insomnia'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Test each case with the best model\n",
    "print(f\"Testing prediction pipeline with {model_info['model_name']} model:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nTest Case {i}:\")\n",
    "    print(f\"Text: {case['text']}\")\n",
    "    print(f\"Expected: {case['expected']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Make prediction\n",
    "    result = predict_mental_health(case['text'])\n",
    "    \n",
    "    if 'error' not in result:\n",
    "        print(f\"Prediction: {result['predicted_class']}\")\n",
    "        if result['confidence']:\n",
    "            print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "        print(f\"Model: {result['model_used']}\")\n",
    "        \n",
    "        # Show top 3 probabilities if available\n",
    "        if result['probabilities']:\n",
    "            sorted_probs = sorted(result['probabilities'].items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "            print(\"Top 3 predictions:\")\n",
    "            for j, (class_name, prob) in enumerate(sorted_probs, 1):\n",
    "                print(f\"  {j}. {class_name}: {prob:.3f}\")\n",
    "    else:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "    \n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45af028",
   "metadata": {},
   "source": [
    "## 5. Interactive Testing\n",
    "\n",
    "Try the model with your own text input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "323270c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Text Analysis:\n",
      "Text: I feel overwhelmed with work and can't seem to manage my stress levels. Everything feels too much.\n",
      "Prediction: Stress\n",
      "Confidence: 0.943\n",
      "Model: Logistic Regression\n",
      "Features: {'num_characters': 98, 'num_sentences': 2, 'num_tokens': 11}\n",
      "\n",
      "Class probabilities:\n",
      "  - Stress: 0.943\n",
      "  - Suicidal: 0.048\n",
      "  - Normal: 0.004\n",
      "  - Depression: 0.003\n",
      "  - Bipolar: 0.000\n",
      "  - Personality disorder: 0.000\n",
      "  - Anxiety: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Interactive testing function\n",
    "def interactive_test():\n",
    "    \"\"\"Interactive function to test custom text input\"\"\"\n",
    "    print(\"Mental Health Text Classifier - Interactive Testing\")\n",
    "    print(\"=\" * 55)\n",
    "    print(f\"Using best model: {model_info['model_name']}\")\n",
    "    print(f\"Model accuracy: {model_info['accuracy']:.4f}\")\n",
    "    print(\"\\nEnter your text below (or type 'quit' to exit):\")\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_text = input(\"\\nEnter text: \")\n",
    "        \n",
    "        if user_text.lower() == 'quit':\n",
    "            print(\"Thank you for testing! 😊\")\n",
    "            break\n",
    "        \n",
    "        if not user_text.strip():\n",
    "            print(\"Please enter some text.\")\n",
    "            continue\n",
    "        \n",
    "        # Make prediction\n",
    "        result = predict_mental_health(user_text)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        if 'error' not in result:\n",
    "            print(f\"Prediction: {result['predicted_class']}\")\n",
    "            if result['confidence']:\n",
    "                print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "            print(f\"Model used: {result['model_used']}\")\n",
    "            print(f\"Text features:\")\n",
    "            for key, value in result['features'].items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "            \n",
    "            # Show probabilities if available\n",
    "            if result['probabilities']:\n",
    "                print(\"\\nAll class probabilities:\")\n",
    "                sorted_probs = sorted(result['probabilities'].items(), key=lambda x: x[1], reverse=True)\n",
    "                for class_name, prob in sorted_probs:\n",
    "                    print(f\"  - {class_name}: {prob:.3f}\")\n",
    "        else:\n",
    "            print(f\"Error: {result['error']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Example usage - uncomment the line below to run interactively\n",
    "# interactive_test()\n",
    "\n",
    "# For demonstration, let's test with a custom example\n",
    "custom_text = \"I feel overwhelmed with work and can't seem to manage my stress levels. Everything feels too much.\"\n",
    "result = predict_mental_health(custom_text)\n",
    "\n",
    "print(\"Custom Text Analysis:\")\n",
    "print(f\"Text: {custom_text}\")\n",
    "print(f\"Prediction: {result['predicted_class']}\")\n",
    "if result['confidence']:\n",
    "    print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "print(f\"Model: {result['model_used']}\")\n",
    "print(f\"Features: {result['features']}\")\n",
    "\n",
    "if result['probabilities']:\n",
    "    print(\"\\nClass probabilities:\")\n",
    "    for class_name, prob in sorted(result['probabilities'].items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  - {class_name}: {prob:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
